{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automation Script Overhaul \n",
    "For automating the parsing, transformation, and geographic file creation from .GPX<br><br>\n",
    "Work taken from the script by Isias (ler_gpx.py) and workflow by Simone. Further developments by Kyle & Isais. <br><br>\n",
    "Data collection must be done with Locus Map 4.x or formatted similarly to GPX files exportd by Locus Map 4 for this script to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1\n",
    "This section takes the raw GPX files and makes them ready for QGIS and statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpxpy\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpxDict = dict()\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file.endswith('.gpx'):\n",
    "       gpxDict[file] = 'file_'+file\n",
    "gpxDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpxList = list(gpxDict)\n",
    "# gpxList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = {} #create empty dictionary\n",
    "merged = pd.DataFrame(columns=['name','lat','lon','ele'])\n",
    "\n",
    "\n",
    "for i in gpxDict:\n",
    "    gpxCurrent = i\n",
    "    gpxCurrent = open(gpxCurrent)\n",
    "    gpxCurrent = gpxpy.parse(gpxCurrent)\n",
    "    gpxCurrent = gpxCurrent.to_xml()\n",
    "    df = pd.read_xml(gpxCurrent) #open and read in the .gpx to a dataframe\n",
    "    df.pop('desc')\n",
    "    df.pop('hdop')\n",
    "    df.pop('time')#remove unecessary columns\n",
    "    df = df.drop(index=0)\n",
    "    shiftPos = df.pop('name')\n",
    "    df.insert(0, 'name', shiftPos)#reorganize columns\n",
    "    # print(df)\n",
    "    df.to_csv('csv', sep=',', index=False)\n",
    "    # d[i] = pd.DataFrame #create dict of datafrmaes created using file names\n",
    "# d\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = {} #create empty dictionary\n",
    "merged = pd.DataFrame(columns=['name','lat','lon','ele'])\n",
    "\n",
    "\n",
    "for i in gpxDict:\n",
    "    gpxCurrent = i\n",
    "    gpxCurrent = open(gpxCurrent)\n",
    "    gpxCurrent = gpxpy.parse(gpxCurrent)\n",
    "    gpxCurrent = gpxCurrent.to_xml()\n",
    "    df = pd.read_xml(gpxCurrent) #open and read in the .gpx to a dataframe\n",
    "    df.pop('desc')\n",
    "    df.pop('hdop')\n",
    "    df.pop('time')#remove unecessary columns\n",
    "    df = df.drop(index=0)\n",
    "    shiftPos = df.pop('name')\n",
    "    df.insert(0, 'name', shiftPos)#reorganize columns)\n",
    "    print(df)\n",
    "    # merged = pd.concat()\n",
    "    # d[i] = pd.DataFrame #create dict of datafrmaes created using file names\n",
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(d.values(), ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('GPX_Exports'):\n",
    "    if file.endswith('.gpx'):\n",
    "        gpxCurrent = file\n",
    "        gpxCurrent = open(gpxCurrent)\n",
    "        gpxCurrent = gpxpy.parse(gpxCurrent)\n",
    "        gpxCurrent = gpxCurrent.to_xml()\n",
    "        # gpxCurrent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependiencies\n",
    "import gpxpy\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# see all GPX files from a saved directory\n",
    "gpxFiles = glob('GPX_Exports/*.gpx')\n",
    "gpxFiles.sort()\n",
    "gpxFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choose the cell below for single file manipulation OR the cell two below for mass import and manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single File Analysis<br>\n",
    "V<br>\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in gpxFiles:\n",
    "    gpxCurrent = gpxFiles[0]\n",
    "    gpxCurrent = open(gpxCurrent)\n",
    "    gpxCurrent = gpxpy.parse(gpxCurrent)\n",
    "    gpxCurrent = gpxCurrent.to_xml()\n",
    "    gpxCurrent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which file to use, select (using 0-n) the gpx file to manipulate / Escolha qual arquivo usar, selecione (usando 0-n) o arquivo gpx para manipular\n",
    "gpxCurrent = gpxFiles[0]\n",
    "gpxCurrent = open(gpxCurrent)\n",
    "gpxCurrent = gpxpy.parse(gpxCurrent)\n",
    "gpxCurrent = gpxCurrent.to_xml()\n",
    "\n",
    "# Read the XML into a dataframe, remove unnecessary columns, and shift columns / Leia o XML em um dataframe, remova colunas desnecessárias e desloque colunas\n",
    "df = pd.read_xml(gpxCurrent)\n",
    "df.pop('desc')\n",
    "df.pop('hdop')\n",
    "df.pop('time')\n",
    "df = df.drop(index=0)\n",
    "shiftPos = df.pop('name')\n",
    "df.insert(0, 'name', shiftPos)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all GPX files in directory / Mesclar todos os arquivos GPX no diretório\n",
    "for i in gpxDict:\n",
    "    df = pd.read_xml(file)\n",
    "    df.pop('desc')\n",
    "    df.pop('hdop')\n",
    "    df.pop('time')\n",
    "    df = df.drop(index=0)\n",
    "    shiftPos = df.pop('name')\n",
    "    df.insert(0, 'name', shiftPos)\n",
    "\n",
    "df = pd.concat(gpxFiles,ignore_index=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to geodataframe for geographic use / Converter para geodataframe para uso geográfico\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df, geometry=gpd.points_from_xy(df.lon, df.lat)) # if Z is wanted for the points, add / se Z for desejado para os pontos, adicione ', df.ele' ex. (df.lon, df.lat, df.ele)\n",
    "gdf = gdf.set_crs('EPSG:4326')\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask for observer, group, climate conditions / Pergunte por observador, grupo, condições climáticas\n",
    "observer = input('Observer/Observador? ')\n",
    "group = input('Group/Grupo? (if both, mark 0) ') # or leave blank?\n",
    "weather = input('Weather conditions/Condição do clima? ')\n",
    "print('Observer/Observador: '+observer)\n",
    "print('Group/Grupo: '+group)\n",
    "print('Weather/Tempo: '+weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " If the above is correct, continue here. If not, re-run the cell and correct the information<br><br>\n",
    " Se o acima estiver correto, continue aqui. Caso contrário, execute novamente a célula e corrija as informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the input to the dataframe\n",
    "gdf.insert(loc=1, column='observer', value=observer, allow_duplicates=True)\n",
    "gdf.insert(loc=1, column='group', value=group, allow_duplicates=True)\n",
    "gdf.insert(loc=1, column='weather', value=weather, allow_duplicates=True)\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 'name' into date, time, and observations / Dividir 'nome' em data, hora e observações\n",
    "date = gdf['name'].str[:10]\n",
    "gdf.insert(loc=0, column='date', value=date, allow_duplicates=True)\n",
    "\n",
    "time = gdf['name'].str[11:19]\n",
    "gdf.insert(loc=1, column='time', value=time, allow_duplicates=True)\n",
    "\n",
    "obs = gdf['name'].str[19:]\n",
    "gdf.insert(loc=2, column='observations', value=obs, allow_duplicates=True)\n",
    "\n",
    "gdf.pop('name')\n",
    "\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split observations into Age/Sex, Strata position, and behaviour\n",
    "# ageSex = ''\n",
    "# strata = ''\n",
    "# behaviour = ''\n",
    "# gdf.insert(loc=2, column='age/sex', value=ageSex, allow_duplicates=True)\n",
    "# gdf.insert(loc=3, column='strata', value=strata, allow_duplicates=True)\n",
    "# gdf.insert(loc=4, column='behaviour', value=behaviour, allow_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run loop to identify age, sex, and behaviour\n",
    "for i, row in gdf.iterrows():\n",
    "        # asSubstring = gdf['observations'].str[:2]\n",
    "        if gdf['observations'].str[:2] == 'j2':\n",
    "                ageSex = 'Juvenile 2'\n",
    "                strata = gdf['observations'].str[2]\n",
    "                behaviour = gdf['observations'].str[3:]\n",
    "                gdf['age/sex']=ageSex\n",
    "                gdf['strata']=strata\n",
    "                gdf['behaviour']=behaviour\n",
    "                \n",
    "\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to detect each scan, else create column for scan number / Tente detectar cada varredura, senão crie uma coluna para o número da varredura\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2\n",
    "Analysis of scans, analyze all of this for every individual scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find centroid of each scan (collect geometries, find centroid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance of each point/animal to centroid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points to polygons for area (ha) of group spread (convex hull)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance between each centroid in temporal order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subgroups/cluster analysis, find clusters on eah scan and distance from each sub-centroid to main group centroid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data frame to gpkg for use in QGIS / Exportar quadro de dados para gpkg para uso no QGIS\n",
    "gdf.to_file('gdf.gpkg', driver=\"GPKG\")\n",
    "gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "721752d912caa1798787a48d49dc55f567da66e2c166f2b94012337a164a3121"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venvScanAutomation': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
